{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003f0e17-8168-4d7a-866f-b8fac7fecb28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data\n",
    "TODO: choose probability/multi-hot/cnn embeddings to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f82ce-726b-4081-8256-8553abb42416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecEQs: (4188, 196) \n",
      "vecEs: (4188, 98) \n",
      "vecQs: (4188, 98) \n",
      "labels: (4188,)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(file_path, colEQ, colE, colQ):\n",
    "    vecEQs = []\n",
    "    vecEs = []\n",
    "    vecQs = []\n",
    "    labels = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            \n",
    "            # str -> ndarray\n",
    "            vecEQ = np.array(eval(row[colEQ]))\n",
    "            \n",
    "            vecE_str = row[colE]\n",
    "            vecE_list = vecE_str.strip('[]').split()\n",
    "            vecE = np.array([float(value) for value in vecE_list])\n",
    "            \n",
    "            vecQ_str = row[colQ]\n",
    "            vecQ_list = vecQ_str.strip('[]').split()\n",
    "            vecQ = np.array([float(value) for value in vecQ_list])\n",
    "            \n",
    "            label = float(row['label'])\n",
    "            \n",
    "            # append\n",
    "            vecEQs.append(vecEQ)\n",
    "            vecEs.append(vecE)\n",
    "            vecQs.append(vecQ)\n",
    "            labels.append(label)\n",
    "    return np.array(vecEQs), np.array(vecEs), np.array(vecQs), np.array(labels)\n",
    "\n",
    "def read_pickle(file_path):\n",
    "    data = pd.read_pickle(file_path)\n",
    "    #display(data)\n",
    "    vecEQs = np.array([np.array((x)) for x in data['predEQ']])\n",
    "    vecEs = np.array([np.array((x)) for x in data['embedE']])\n",
    "    vecQs = np.array([np.array((x)) for x in data['embedQ']])\n",
    "    labels = data['label'].astype(float).values\n",
    "    return vecEQs, vecEs, vecQs, labels\n",
    "\n",
    "\n",
    "# read prob.: good_embedding_probEQ.csv, bad_embedding_probEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/good_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/bad_embedding_probEQ.csv', 'probEQ', 'probE', 'probQ')\n",
    "\n",
    "\n",
    "'''\n",
    "# read multi-hot: good_embedding_predEQ.csv, bad_embedding_predEQ.csv\n",
    "\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_csv('../embeddings/good_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_csv('../embeddings/bad_embedding_predEQ.csv', 'predEQ', 'predE', 'predQ')\n",
    "'''\n",
    "\n",
    "'''\n",
    "# read cnn: good_embedding.pkl, bad_embedding.pkl\n",
    "vecEQs_good, vecEs_good, vecQs_good, labels_good = read_pickle('../embeddings/CNN(Resnet50)/good_embedding.pkl')\n",
    "vecEQs_bad, vecEs_bad, vecQs_bad, labels_bad = read_pickle('../embeddings/CNN(Resnet50)/bad_embedding.pkl')\n",
    "'''\n",
    "\n",
    "# 合併 good & bad data, check shape\n",
    "vecEQs = np.concatenate((vecEQs_good, vecEQs_bad), axis=0)\n",
    "vecEs = np.concatenate((vecEs_good, vecEs_bad), axis=0)\n",
    "vecQs = np.concatenate((vecQs_good, vecQs_bad), axis=0)\n",
    "labels = np.concatenate((labels_good, labels_bad), axis=0)\n",
    "\n",
    "print(\"vecEQs:\", vecEQs.shape, \"\\nvecEs:\", vecEs.shape, \"\\nvecQs:\", vecQs.shape, \"\\nlabels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5693a4-912a-46e8-9da6-adfa81f9b587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (12564, 196) \n",
      "X^: (12564, 196)\n"
     ]
    }
   ],
   "source": [
    "# X: EQ, E0, 0Q\n",
    "zeros = np.zeros_like(vecEs)\n",
    "x1 = vecEQs\n",
    "x2 = np.hstack((vecEs, zeros))\n",
    "x3 = np.hstack((zeros, vecQs))\n",
    "x123 = np.vstack((x1, x2, x3))\n",
    "\n",
    "# X^: EQ, EQ, EQ\n",
    "y123 = np.vstack((x1, x1, x1))\n",
    "\n",
    "print(\"X:\", x123.shape, \"\\nX^:\", y123.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdef848-34cd-47fc-8d90-87b2cd5dd342",
   "metadata": {
    "tags": []
   },
   "source": [
    "### model\n",
    "TODO: 注意 training 要丟入的 x, x^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432f2484-15cb-4290-a3ea-82e5dd0ac76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 18:30:05.320551: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 196)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 147)               28959     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 98)                14504     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 147)               14553     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 196)               29008     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87024 (339.94 KB)\n",
      "Trainable params: 87024 (339.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 196 >> 147 >> 98 >> 147 >> 196\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# given vecEQs\n",
    "input_dim = vecEQs.shape[1]\n",
    "\n",
    "# encoder layer (196 >> 147 >> 98)\n",
    "encoding_dim1 = 147\n",
    "encoding_dim2 = 98\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1, activation='relu')(input_layer)\n",
    "encoded2 = Dense(encoding_dim2, activation='relu')(encoded1)\n",
    "\n",
    "# decoder layer (98 >> 147 >> 196)\n",
    "decoded1 = Dense(encoding_dim1, activation='relu')(encoded2)\n",
    "decoded2 = Dense(input_dim, activation='sigmoid')(decoded1)\n",
    "\n",
    "# encoder-decoder(196 >> 147 >> 98 >> 147 >> 196)\n",
    "autoencoder = Model(input_layer, decoded2)\n",
    "\n",
    "# encoder model\n",
    "encoder = Model(input_layer, encoded2)\n",
    "\n",
    "# decoder model\n",
    "encoded_input = Input(shape=(encoding_dim2,))\n",
    "decoder_layer1 = autoencoder.layers[-2]\n",
    "decoder_layer2 = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer2(decoder_layer1(encoded_input)))\n",
    "\n",
    "# compile model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8e00c1-b01e-4f7d-be0d-1243d2452eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 0.1657 - val_loss: 0.0894\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0041\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 9.3395e-04\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 8.9215e-04\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.9345e-04 - val_loss: 8.6816e-04\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.6864e-04 - val_loss: 8.3983e-04\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.3811e-04 - val_loss: 8.0570e-04\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0083e-04 - val_loss: 7.6908e-04\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.6099e-04 - val_loss: 7.3254e-04\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.2414e-04 - val_loss: 7.0446e-04\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.9545e-04 - val_loss: 6.8576e-04\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.7657e-04 - val_loss: 6.6687e-04\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.6180e-04 - val_loss: 6.5974e-04\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.4989e-04 - val_loss: 6.4923e-04\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.3694e-04 - val_loss: 6.4251e-04\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.2407e-04 - val_loss: 6.3479e-04\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 7.0545e-04 - val_loss: 6.2407e-04\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 6.8065e-04 - val_loss: 6.0367e-04\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 6.5297e-04 - val_loss: 5.7556e-04\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 6.1983e-04 - val_loss: 5.5194e-04\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.8759e-04 - val_loss: 5.2769e-04\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.5909e-04 - val_loss: 5.0312e-04\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.3131e-04 - val_loss: 4.8344e-04\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.0805e-04 - val_loss: 4.6377e-04\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 4.8696e-04 - val_loss: 4.5156e-04\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.6835e-04 - val_loss: 4.3556e-04\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.5010e-04 - val_loss: 4.2417e-04\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 4.3358e-04 - val_loss: 4.1261e-04\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 4.1733e-04 - val_loss: 4.0228e-04\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 4.0244e-04 - val_loss: 3.9207e-04\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 3.8715e-04 - val_loss: 3.7909e-04\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 3.7301e-04 - val_loss: 3.6793e-04\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 3.5767e-04 - val_loss: 3.5381e-04\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.4526e-04 - val_loss: 3.4239e-04\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.3565e-04 - val_loss: 3.3479e-04\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 3.2808e-04 - val_loss: 3.2825e-04\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3.2222e-04 - val_loss: 3.2319e-04\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 3.1792e-04 - val_loss: 3.1750e-04\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3.1421e-04 - val_loss: 3.1485e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb7b574aac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "autoencoder.fit(vecEQs, vecEQs, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n",
    "#autoencoder.fit(x123, y123, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4413938e-a84a-48e1-8cef-9d531c9964fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s 893us/step\n"
     ]
    }
   ],
   "source": [
    "# middle layer\n",
    "middle_vecEQs = encoder.predict(vecEQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30467eb4-c5a2-4bcb-9027-d83cbfec344c",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa3894a-2c7c-4af1-9b5b-112c195aabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM] MSE = 0.2757061123247706, MAE = 0.49519324570681217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(middle_vecEQs, labels, test_size=0.2, random_state=42, stratify = labels)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVR(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE, MAE\n",
    "y_pred = svm_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[SVM] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d863ec-cdff-4fec-9e0d-9f3f35292d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] MSE = 0.2589729116945107, MAE = 0.4897494033412888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# MSE\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[RF] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3017775f-0c99-4a75-ae9f-ba8a64e4f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "84/84 [==============================] - 1s 3ms/step - loss: 0.2583 - val_loss: 0.2502\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2539 - val_loss: 0.2497\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2539 - val_loss: 0.2498\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2517 - val_loss: 0.2494\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2520 - val_loss: 0.2503\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2521 - val_loss: 0.2501\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2511 - val_loss: 0.2564\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2509 - val_loss: 0.2489\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 0.2495\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 0.2502\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2525 - val_loss: 0.2488\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2495\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2500 - val_loss: 0.2502\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2482 - val_loss: 0.2506\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2479 - val_loss: 0.2595\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2497 - val_loss: 0.2484\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2489 - val_loss: 0.2465\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2471 - val_loss: 0.2507\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2483 - val_loss: 0.2487\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2475 - val_loss: 0.2470\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "[NN] MSE = 0.24760135830766278, MAE = 0.49538292847840487\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural Network model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(16, activation='sigmoid'))\n",
    "nn_model.add(Dense(1))  # output layer\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# training\n",
    "nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# MSE\n",
    "y_pred = nn_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'[NN] MSE = {mse}, MAE = {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdf5c9-4c6f-4441-9854-d3f9ef63f9c7",
   "metadata": {},
   "source": [
    "### 手動 record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3128d44a-e096-4f38-a690-9f6d6173f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料集(EQ)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.275706</td>\n",
       "      <td>0.311330</td>\n",
       "      <td>0.254638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.258973</td>\n",
       "      <td>0.268861</td>\n",
       "      <td>0.238933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.247601</td>\n",
       "      <td>0.252473</td>\n",
       "      <td>0.242192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.275706   0.311330  0.254638\n",
       "rf      0.258973   0.268861  0.238933\n",
       "nn      0.247601   0.252473  0.242192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "三倍資料集(EQ, E0, 0Q)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>multi-hot</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.283773</td>\n",
       "      <td>0.318831</td>\n",
       "      <td>0.233024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.261314</td>\n",
       "      <td>0.236585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.248409</td>\n",
       "      <td>0.256502</td>\n",
       "      <td>0.243901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  multi-hot       cnn\n",
       "svm     0.283773   0.318831  0.233024\n",
       "rf      0.261029   0.261314  0.236585\n",
       "nn      0.248409   0.256502  0.243901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'probability': [0.2757061123247706, 0.2589729116945107, 0.24760135830766278],\n",
    "    'multi-hot': [0.3113301803055666, 0.26886112194829226, 0.2524728533771422],\n",
    "    'cnn': [0.25463821738103376, 0.23893257756563246, 0.24219229685222451]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=['svm', 'rf', 'nn'])\n",
    "print(\"原始資料集(EQ)\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "data2 = {\n",
    "    'probability': [0.2837730806873752, 0.2610291169451074, 0.2484090777202349],\n",
    "    'multi-hot': [0.3188305040862045, 0.2613142604766219, 0.2565020791026134],\n",
    "    'cnn': [0.23302369784904192, 0.2365852028639618, 0.24390136605141902]\n",
    "}\n",
    "\n",
    "print(\"\\n三倍資料集(EQ, E0, 0Q)\")\n",
    "df2 = pd.DataFrame(data2, index=['svm', 'rf', 'nn'])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbff5f-8f9e-4a4e-bae0-7f95a4af7da4",
   "metadata": {},
   "source": [
    "### end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
