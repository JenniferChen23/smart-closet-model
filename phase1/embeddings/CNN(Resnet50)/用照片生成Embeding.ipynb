{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0469d7",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29f6fd",
   "metadata": {},
   "source": [
    "Image Similarity using CNN feature embeddings\n",
    "https://github.com/totogot/ImageSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87eaf1",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382f786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chen\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class Img2Vec:\n",
    "    def __init__(self, model_name='resnet50', weights='DEFAULT'):\n",
    "        self.architecture = model_name\n",
    "        self.weights = weights\n",
    "        self.transform = self.assign_transform(weights)\n",
    "        self.device = self.set_device()\n",
    "        self.model = self.initiate_model()\n",
    "        self.embed = self.assign_layer()\n",
    "        print(\"Model initialized\")\n",
    "\n",
    "    def assign_transform(self, weights):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def set_device(self):\n",
    "        return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def initiate_model(self):\n",
    "        model = getattr(models, self.architecture)(weights=self.weights)\n",
    "        model.to(self.device)\n",
    "        return model.eval()\n",
    "\n",
    "    def assign_layer(self):\n",
    "        return nn.Sequential(*list(self.model.children())[:-1])\n",
    "\n",
    "    def embed_image(self, img_path):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_trans = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embedding = self.embed(img_trans)\n",
    "        return embedding.squeeze()\n",
    "    \n",
    "\n",
    "    def embed_images(self, upper_img_path, lower_img_path):\n",
    "        upper_embedding = self.embed_image(upper_img_path)\n",
    "        lower_embedding = self.embed_image(lower_img_path)\n",
    "        #print(f\"Upper image tensor shape: {upper_embedding}\")\n",
    "        #print(f\"Lower image tensor shape: {lower_image_tensor.shape}\")\n",
    "        # Concatenate the two embeddings\n",
    "        combined_embedding = torch.cat((upper_embedding, lower_embedding), dim=0)\n",
    "        \n",
    "        return upper_embedding, lower_embedding, combined_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a027378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "Combined embedding shape: (4096,)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# 创建一个空的 DataFrame\n",
    "data = {\n",
    "    'idxE': [],\n",
    "    'idxQ': [],\n",
    "    'img_pathE': [],\n",
    "    'img_pathQ':[],\n",
    "    'predEQ': [],\n",
    "    'label': [],\n",
    "    'embedE': [],\n",
    "    'embedQ': []\n",
    "}\n",
    "\n",
    "img2vec = Img2Vec('resnet50', weights='IMAGENET1K_V2')\n",
    "\n",
    "\n",
    "df=pd.read_csv(r'C:\\Users\\chen\\資管專題\\bad_outfits.csv')\n",
    "df['predEQ'] = None\n",
    "df['label'] = None\n",
    "df['embedE'] = None\n",
    "df['embedQ'] = None\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    upper_picture_path = df.at[index, 'img_pathE'].replace(':', '_').replace('../new_data/cut_style', 'C://Users//chen//資管專題//data//cut_style')\n",
    "    lower_picture_path = df.at[index, 'img_pathQ'].replace(':', '_').replace('../new_data/cut_style', 'C://Users//chen//資管專題//data//cut_style')\n",
    "    \n",
    "    upper_embedding, lower_embedding, combined_embedding = img2vec.embed_images(upper_picture_path, lower_picture_path)\n",
    "    \n",
    "    upper_embedding = np.array(upper_embedding)\n",
    "    lower_embedding = np.array(lower_embedding)\n",
    "    combined_embedding = np.array(combined_embedding)\n",
    "    \n",
    "    df.at[index, 'label'] = 0\n",
    "    df.at[index, 'predEQ'] = ','.join(map(str, combined_embedding))\n",
    "    df.at[index, 'embedE'] = ','.join(map(str, upper_embedding))\n",
    "    df.at[index, 'embedQ'] = ','.join(map(str, lower_embedding))\n",
    "    \n",
    "df.to_csv('bad_embedding_cnn.csv', index=False)\n",
    "print(f\"Combined embedding shape: {combined_embedding.shape}\")\n",
    "print('ok')\n",
    "# df['img_pathE'] = df['img_pathE'].str.replace(':', '_').str.replace('../new_data/cut_style', 'C://Users//chen//資管專題//data//cut_style')\n",
    "# df['img_pathQ'] = df['img_pathQ'].str.replace(':', '_').str.replace('../new_data/cut_style', 'C://Users//chen//資管專題//data//cut_style')\n",
    "# print(df.head())\n",
    "\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63c1655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# 创建一个空的 DataFrame\n",
    "data = {\n",
    "    'index': [],\n",
    "    'img_path': [],\n",
    "    'predEQ': [],\n",
    "    'label': [],\n",
    "    'embedE': [],\n",
    "    'embedQ': []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "img2vec = Img2Vec('resnet50', weights='IMAGENET1K_V2')\n",
    "\n",
    "three_style = ['korea','japan','america']\n",
    "three_style_index={'korea':'2','japan':'1','america':'0'}\n",
    "three_style_each_num =1059\n",
    "ten_occation=['wedding_guest','travel','sports','shopping','school','porm','party','dating','daily_work','conference']\n",
    "ten_occation_index={'wedding_guest':'12','travel':'5','sports':'6','shopping':'9','school':'11','porm':'8','party':'10','dating':'3','daily_work':'4','conference':'7'}\n",
    "ten_occation_each_num = 1005\n",
    "\n",
    "\n",
    "for style in three_style:\n",
    "    file_path='C://Users//chen//資管專題//data//'+'cut_style_'+ style +'//'\n",
    "    for i in range(1,three_style_each_num+1):\n",
    "        img_path = '../new_data/style:'+style+'/'+ str(i)+'.jpg'\n",
    "        upper_picture = three_style_index[style]+'_'+str(i)+'_E_.jpg'\n",
    "        lower_picture = three_style_index[style]+'_'+str(i)+'_Q_.jpg'\n",
    "    #upper_embedding, lower_embedding, combined_embedding = img2vec.embed_images(r\"C:\\Users\\chen\\資管專題\\skirt.png\", r\"C:\\Users\\chen\\資管專題\\skirt.png\")\n",
    "\n",
    "        upper_picture_path = os.path.join(file_path, upper_picture)\n",
    "        lower_picture_path = os.path.join(file_path, lower_picture)\n",
    "\n",
    "        if os.path.exists(lower_picture_path)==False and os.path.exists(upper_picture_path)==False:\n",
    "            continue\n",
    "        elif os.path.exists(lower_picture_path)==False:\n",
    "            upper_embedding = img2vec.embed_image(upper_picture_path)\n",
    "            lower_embedding=None\n",
    "            combined_embedding=None\n",
    "        elif os.path.exists(upper_picture_path)==False:\n",
    "            lower_embedding = img2vec.embed_image(lower_picture_path)\n",
    "            upper_embeddin=None\n",
    "            combined_embedding=None\n",
    "        else:\n",
    "            upper_embedding, lower_embedding, combined_embedding = img2vec.embed_images(upper_picture_path, lower_picture_path)\n",
    "        \n",
    "        # Convert to numpy arrays if not None\n",
    "        if upper_embedding is not None:\n",
    "            upper_embedding = np.array(upper_embedding)\n",
    "        if lower_embedding is not None:\n",
    "            lower_embedding = np.array(lower_embedding)\n",
    "        if combined_embedding is not None:\n",
    "            combined_embedding = np.array(combined_embedding)\n",
    "            \n",
    "        #print(f\"Upper embedding: {upper_embedding}\")\n",
    "        #print(three_style_index[style]+'_'+str(i))\n",
    "        data['index'].append(three_style_index[style] + '_' + str(i))\n",
    "        data['img_path'].append(img_path)\n",
    "        data['predEQ'].append(combined_embedding)\n",
    "        data['embedE'].append(upper_embedding)\n",
    "        data['embedQ'].append(lower_embedding)\n",
    "        data['label'].append(1)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    name = 'cut_style_'+ style+'.csv'\n",
    "    df.to_csv(name, index=False)\n",
    "    print('ok')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7710456",
   "metadata": {},
   "source": [
    "# 產生糟糕的配對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1aefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Upper embedding shape: {upper_embedding.shape}\")\n",
    "print(f\"Upper embedding: {upper_embedding}\")\n",
    "print(f\"Lower embedding shape: {lower_embedding.shape}\")\n",
    "print(f\"Lower embedding shape: {lower_embedding}\")\n",
    "print(f\"Combined embedding shape: {combined_embedding.shape}\")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dating：3\n",
    "Daily Work：4\n",
    "Travel：5\n",
    "Sports：6\n",
    "Conference：7\n",
    "Prom：8\n",
    "Shopping：9\n",
    "Party：10\n",
    "School：11\n",
    "Wedding Guest：12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62383130",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/CVxTz/image-and-text-embeddings-resnet-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8a33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423baa8",
   "metadata": {},
   "source": [
    "# OpenAI clip api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14552a",
   "metadata": {},
   "source": [
    "https://medium.com/@highsunday0630/image-embedding-1-clip%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96-image-embedding-%E4%B8%A6%E4%BB%A5-tensorboard-%E8%A6%96%E8%A6%BA%E5%8C%96%E6%95%88%E6%9E%9C-dc281370d7d8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
